{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d23f8bf2",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup to Webscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95124b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests #to load the page \n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm #good to have\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver ## webdriver is the tool to interact with the webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b6e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate target dictionary we want from billboard. This will be turned into a dataframe after scraping from billboard.\n",
    "\n",
    "dict = {\n",
    "    \"id\": [],\n",
    "    \"Song title\": [],\n",
    "    \"Artist\": [],\n",
    "    \"Current Ranking\": [],\n",
    "    \"Number of weeks on billboard\": [],\n",
    "    \"Peak Ranking\": [],\n",
    "    \"Date\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ce5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a list of sundays in 2022\n",
    "dates = []\n",
    "date = datetime.date(2022, 1, 1)\n",
    "while (date.year == 2022):\n",
    "    dates.append(date)\n",
    "    date = date + timedelta(days = 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18430ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define helper functions\n",
    "\n",
    "#converts datetime to required date format for url\n",
    "def convert_date(date):\n",
    "    year = str(date.year)\n",
    "    month = str(date.month)\n",
    "    day = str(date.day)\n",
    "    if len(year) == 1:\n",
    "        year = \"0\" + year\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "    return year + \"-\" + month + \"-\" + day +\"/\"\n",
    "\n",
    "#updates dictionary of songs\n",
    "\n",
    "def update_dict(d, ids, titles, artists, rankings, weeks, peaks, dates):\n",
    "    d[\"id\"].extend(ids)\n",
    "    d[\"Song title\"].extend(titles)\n",
    "    d[\"Artist\"].extend(artists)\n",
    "    d[\"Current Ranking\"].extend(rankings)\n",
    "    d[\"Number of weeks on billboard\"].extend(weeks)\n",
    "    d[\"Peak Ranking\"].extend(peaks)\n",
    "    d[\"Date\"].extend(dates)\n",
    "\n",
    "def scrape_page(url,date, id):\n",
    "    #initialize target lists\n",
    "    ids = list(range(id + 1, id + 201))\n",
    "    dates = [date]*200\n",
    "    titles = []\n",
    "    artists = []\n",
    "    rankings = list(range(1, 201))\n",
    "    weeks = []\n",
    "    peaks = []\n",
    "\n",
    "    #get page\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    #get titles\n",
    "    #get first title\n",
    "    title = page.find(\"h3\", attrs = {\"class\":\"c-title a-font-primary-bold-l a-font-primary-bold-m@mobile-max lrv-u-color-black u-color-white@mobile-max lrv-u-margin-r-150\"}).find(\"a\").string.strip()\n",
    "    titles.append(title)\n",
    "    scrape_titles = page.find_all(\"h3\", attrs = {\"class\": \"c-title a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only\"})\n",
    "    for t in scrape_titles:\n",
    "        title = t.string.strip()\n",
    "        titles.append(title)\n",
    "    \n",
    "    #get artists\n",
    "    #get first artist\n",
    "    artist = page.find(\"span\", attrs = {\"class\": \"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet\"}).string.strip()\n",
    "    artists.append(artist)\n",
    "    scrape_artists = page.find_all(\"span\", attrs = {\"class\": \"c-label a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"})\n",
    "    for a in scrape_artists:\n",
    "        artist = a.string.strip()\n",
    "        artists.append(artist)\n",
    "\n",
    "    #get peak and weeks for first song\n",
    "    weeks1 = page.find_all(\"span\", attrs = {\"class\": \"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet\"})\n",
    "    lst = []\n",
    "    for i in weeks1:\n",
    "        lst.append(i.string.strip())\n",
    "    peaks.append(lst[1])\n",
    "    weeks.append(lst[2])\n",
    "\n",
    "    #get peak and weeks for rest of the songs\n",
    "    weeks2 = page.find_all(\"span\", attrs = {\"class\":\"c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max\"})\n",
    "    lst2 = []\n",
    "    for i in weeks2:\n",
    "        lst2.append(i.string.strip())\n",
    "    for i in range(0, 1190, 6):\n",
    "        peaks.append(lst2[i + 1])\n",
    "        weeks.append(lst2[i + 2])\n",
    "    update_dict(dict, ids, titles, artists, rankings, weeks, peaks, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f963d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.billboard.com/charts/billboard-global-200/2022-01-01/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-01-08/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-01-15/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-01-22/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-01-29/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-02-05/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-02-12/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-02-19/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-02-26/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-03-05/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-03-12/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-03-19/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-03-26/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-04-02/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-04-09/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-04-16/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-04-23/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-04-30/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-05-07/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-05-14/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-05-21/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-05-28/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-06-04/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-06-11/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-06-18/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-06-25/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-07-02/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-07-09/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-07-16/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-07-23/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-07-30/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-08-06/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-08-13/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-08-20/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-08-27/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-09-03/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-09-10/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-09-17/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-09-24/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-10-01/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-10-08/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-10-15/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-10-22/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-10-29/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-11-05/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-11-12/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-11-19/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-11-26/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-12-03/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-12-10/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-12-17/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-12-24/\n",
      "https://www.billboard.com/charts/billboard-global-200/2022-12-31/\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for date in dates:\n",
    "    url = \"https://www.billboard.com/charts/billboard-global-200/\" + convert_date(date)\n",
    "    print(url)\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser') \n",
    "    scrape_page(url, date, counter)\n",
    "    counter += 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df914181",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dict)\n",
    "data.to_csv(\"billboard.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
