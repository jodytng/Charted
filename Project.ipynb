{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95124b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests #to load the page \n",
    "import csv\n",
    "import time\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm #good to have\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver ## webdriver is the tool to interact with the webpage \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14e2b639",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched '}' (3155984986.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/_f/3fs6vlxj07v9cgw4s2z4b6d40000gn/T/ipykernel_21012/3155984986.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def scrape_single_page(reviews, output, name):}\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched '}'\n"
     ]
    }
   ],
   "source": [
    "def scrape_single_page(reviews, output, name):\n",
    "    for review in reviews: \n",
    "        date = review.find('span', attrs={'class':'css-chan6m'}).string\n",
    "        content = review.find('span', attrs={'class':'raw_09f24_T4Ezm'}).text.strip()\n",
    "        raw = review.find('span',attrs={'class':'raw_09f24_T4Ezm'}).get_text\n",
    "        temp = []\n",
    "        temp.append(name)\n",
    "        temp.append(date)\n",
    "        temp.append(content)\n",
    "        temp.append(raw)\n",
    "        votes = review.find_all('span', attrs={'class':'css-12i50in'})\n",
    "        for vote in votes:\n",
    "            count = vote.find('span', attrs={'class':'css-1lr1m88'})\n",
    "            if count: \n",
    "                temp.append(count.text)\n",
    "            else: \n",
    "                temp.append('0')\n",
    "                \n",
    "        ## fails if there are revised reviews\n",
    "        rating = review.find('div', attrs={'class':'star-rating'#change this accordingly})\n",
    "        if rating: \n",
    "            temp.append('5')\n",
    "        rating = review.find('div', attrs={'class':'star-rating'#change this accordingly})\n",
    "        if rating: \n",
    "            temp.append('4')\n",
    "        rating = review.find('div', attrs={'class':'star-rating'#change this accordingly})\n",
    "        if rating: \n",
    "            temp.append('3')\n",
    "        rating = review.find('div', attrs={'class':'star-rating'#change this accordingly})\n",
    "        if rating: \n",
    "            temp.append('2')\n",
    "        rating = review.find('div', attrs={'class':'star-rating'#change this accordingly})\n",
    "        if rating: \n",
    "            temp.append('1')\n",
    "        output.append(temp)\n",
    "\n",
    "header = ['name','date','content','raw','useful','funny','cool','rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f963d67",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'restaurant_list.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_f/3fs6vlxj07v9cgw4s2z4b6d40000gn/T/ipykernel_21012/1360283961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'restaurant_list.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf_8_sig'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcsvreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrestaurant_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsvreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'restaurant_list.csv'"
     ]
    }
   ],
   "source": [
    "file = open('restaurant_list.csv', encoding = 'utf_8_sig')\n",
    "csvreader = csv.reader(file)\n",
    "restaurant_list = []\n",
    "next(csvreader) \n",
    "for row in csvreader: \n",
    "    url = row[1]\n",
    "    restaurant_list.append(url)\n",
    "file.close()\n",
    "\n",
    "for url in restaurant_list: \n",
    "    output = []\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')  \n",
    "    \n",
    "    #scrape the name of the restaurant \n",
    "    name = page.find('h1', attrs = {'class': 'css-12dgwvn'}).text #inspect html \n",
    "    reviews = page.find_all('div', attrs = {'class': 'css-12dgwvn'}) #inspect html \n",
    "    scrape_single_page(reviews, output, name)\n",
    "    \n",
    "    num_reviews = page.find('span', attrs = {'class': 'css-12dgwvn'}).string\n",
    "    num_reviews = int(num_reviews.split('')[0])\n",
    "    page_section = page.find('div', attrs = {'class': 'css-12dgwvn'})\n",
    "    num_pages = page_section.find('span', attrs = {'class': 'css-12dgwvn'}).text\n",
    "    num_pages = int(num_pages.split('')[-1]) - 1 \n",
    "    \n",
    "    url_list = []\n",
    "    for i in range(10, num_pages*10, 10):\n",
    "        url_list.append(url + '?start=' + str(i))\n",
    "        \n",
    "        \n",
    "    print(name + ' ; ' + str(num_pages) + ' ; ' + strlen((url_list)) + ' ; ' + str(num_reviews))\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for new_url in tqdm(url_list): \n",
    "        num_reviews = 0\n",
    "        sleep_time = 10\n",
    "        sleep_num = 0\n",
    "        \n",
    "        while num_reviews == 0: \n",
    "            time.sleep(sleep_time)\n",
    "            sleep_num += 1\n",
    "            response = requests.get(new_url)\n",
    "            page = BeautifulSoup(response.text, 'html_parser')\n",
    "            reviews = page.find_all('div', attrs = {'class': '.....'}) #inspect html\n",
    "            num_reviews = len(reviews)\n",
    "            if sleep_num > 2: \n",
    "                print(\"sleep more than 3 for: \" + new_url)\n",
    "        scrape_single_page(reviews, output, name)\n",
    "        \n",
    "    cur_size = len(output)\n",
    "    print('newly added: ' + str(cur_size))\n",
    "    \n",
    "    file name = name + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df914181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
